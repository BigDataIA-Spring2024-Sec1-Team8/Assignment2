{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import csv\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resources/grobid/xml/Level1_combined.grobid.tei.xml\n",
      "resources/grobid/xml/Level2_combined.grobid.tei.xml\n",
      "resources/grobid/xml/Level3_combined.grobid.tei.xml\n",
      "Combined CSV file 'resources/grobid/outcomes.csv' created successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# List of XML file paths\n",
    "xml_file_paths = ['resources/grobid/xml/Level1_combined.grobid.tei.xml', 'resources/grobid/xml/Level2_combined.grobid.tei.xml','resources/grobid/xml/Level3_combined.grobid.tei.xml']\n",
    "\n",
    "# Create a CSV file\n",
    "csv_filename = 'resources/grobid/outcomes.csv'\n",
    "\n",
    "with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    \n",
    "    # Write header\n",
    "    csv_writer.writerow(['Topic', 'Learning Outcomes Section'])\n",
    "    \n",
    "    # Iterate through each XML file\n",
    "    for xml_file_path in xml_file_paths:\n",
    "        print(xml_file_path)\n",
    "        # Read the XML data from the file\n",
    "        with open(xml_file_path, 'r') as file:\n",
    "            xml_data = file.read()\n",
    "        # Parse the XML data\n",
    "        root = ET.fromstring(xml_data)\n",
    "\n",
    "        for div_element in root.findall('.//{http://www.tei-c.org/ns/1.0}div'):\n",
    "                head_element = div_element.find('.//{http://www.tei-c.org/ns/1.0}head')\n",
    "\n",
    "                p_elements = div_element.findall('.//{http://www.tei-c.org/ns/1.0}p')\n",
    "\n",
    "                combined_p_text = ' '.join(p_element.text for p_element in p_elements if p_element.text)\n",
    "                if combined_p_text != '':\n",
    "                    csv_writer.writerow([head_element.text if head_element is not None else '', combined_p_text])\n",
    "\n",
    "print(f\"Combined CSV file '{csv_filename}' created successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_whitespaces(value):\n",
    "    if isinstance(value, str):\n",
    "        return ' '.join(value.split())\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "def preprocess_text(value):\n",
    "    if isinstance(value, str):\n",
    "        return f'\"{value}\"'\n",
    "    else:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has been uploaded to S3 at s3://cfainstitute-learning-outcomes-raw/outcomes_processed.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "aws_access_key_id = os.getenv('aws_access_key_id')\n",
    "aws_secret_access_key = os.getenv('aws_secret_access_key')\n",
    "bucket_name = 'cfainstitute-learning-outcomes-raw'\n",
    "\n",
    "df = pd.read_csv('resources/grobid/outcomes.csv', dtype=str)\n",
    "df = df.map(remove_extra_whitespaces)\n",
    "df = df.map(preprocess_text)\n",
    "\n",
    "df.to_csv('resources/grobid/outcomes_processed.csv', index=False)\n",
    "\n",
    "s3 = boto3.client('s3', aws_access_key_id=aws_access_key_id, aws_secret_access_key=aws_secret_access_key)\n",
    "\n",
    "csv_data = df.to_csv(index=False)\n",
    "\n",
    "s3_key = 'outcomes_processed.csv'\n",
    "\n",
    "s3.put_object(Body=csv_data, Bucket=bucket_name, Key=s3_key)\n",
    "\n",
    "print(f\"CSV file has been uploaded to S3 at s3://{bucket_name}/{s3_key}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to snowflake from local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "snowflake_account = os.getenv('snowflake_account')\n",
    "snowflake_user = os.getenv('snowflake_user')\n",
    "snowflake_password = os.getenv('snowflake_password')\n",
    "snowflake_warehouse = os.getenv('snowflake_warehouse')\n",
    "snowflake_schema = os.getenv('snowflake_schema')\n",
    "snowflake_database = 'your_database'\n",
    "\n",
    "engine = create_engine(\n",
    "    'snowflake://{user}:{password}@{account_identifier}/'.format(\n",
    "        user=snowflake_user,\n",
    "        password=snowflake_password,\n",
    "        account_identifier=snowflake_account,\n",
    "    )\n",
    ")\n",
    "connection = engine.connect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create table and db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.cursor.LegacyCursorResult at 0x115ee60d0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_database = 'CFAInstitute'\n",
    "target_table = 'Topic_Learning_Outcomes'\n",
    "\n",
    "create_database_query = f\"CREATE DATABASE IF NOT EXISTS {target_database}\"\n",
    "connection.execute(create_database_query)\n",
    "\n",
    "use_database_query = f\"USE DATABASE {target_database}\"\n",
    "connection.execute(use_database_query)\n",
    "connection.execute(\"USE WAREHOUSE TEST\")\n",
    "\n",
    "create_table_query = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {target_table} (\n",
    "    Topic VARCHAR,\n",
    "    \"Learning Outcomes Section\" VARCHAR\n",
    "    \n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "connection.execute(create_table_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.cursor.LegacyCursorResult at 0x115db7d90>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connection.execute(f\"TRUNCATE TABLE {target_table}\")\n",
    "\n",
    "connection.execute(f\"PUT file://resources/grobid/outcomes_processed.csv @%{target_table}\")\n",
    "\n",
    "connection.execute(f\"COPY INTO {target_table} ON_ERROR=CONTINUE FILE_FORMAT = (FIELD_OPTIONALLY_ENCLOSED_BY = '\\\"' SKIP_HEADER=1 PARSE_HEADER = FALSE)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# upload to snowflake from s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.cursor.LegacyCursorResult at 0x115b43ed0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connection.execute(\"\"\"CREATE OR REPLACE FILE FORMAT mycsvformat\n",
    "   TYPE = 'CSV'\n",
    "   FIELD_DELIMITER = '|'\n",
    "   SKIP_HEADER = 1;\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Goto iam of aws and create a role\n",
    " use above role arn to create storage integration\n",
    " Create STORAGE INTEGRATION that can connect to aws account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cursor.execute(\"\"\"CREATE OR REPLACE STORAGE INTEGRATION s3_int2\n",
    "#   TYPE = EXTERNAL_STAGE\n",
    "#   STORAGE_PROVIDER = 'S3'\n",
    "#   STORAGE_AWS_ROLE_ARN = 'arn:aws:iam::640055273174:role/s3-read'\n",
    "#   ENABLED = TRUE\n",
    "#   STORAGE_ALLOWED_LOCATIONS = ('*')\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " go to trusted relationships of iam role created in above step from aws console and change it to below template\n",
    "```\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"s3.amazonaws.com\",\n",
    "                \"AWS\": \"<user arn>\"\n",
    "            },\n",
    "            \"Action\": \"sts:AssumeRole\",\n",
    "            \"Condition\": {\n",
    "                \"StringEquals\": {\n",
    "                    \"sts:ExternalId\": \"<external id>\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "run \"DESC Integration s3_int2\"  inside snowflake to get STORAGE_AWS_IAM_USER_ARN and STORAGE_AWS_EXTERNAL_ID of storage integration crreated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connection.execute(\"\"\"CREATE OR REPLACE STAGE external_stage\n",
    "#   FILE_FORMAT = mycsvformat\n",
    "#   URL = 's3://cfainstitute-learning-outcomes-raw/outcomes.csv'\n",
    "#   STORAGE_INTEGRATION = s3_int2;\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to snowflake from s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.cursor.LegacyCursorResult at 0x115c86550>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connection.execute(\"\"\"\n",
    "copy into Topic_Learning_Outcomes\n",
    "from 's3://cfainstitute-learning-outcomes-raw/outcomes_processed.csv'\n",
    "storage_integration = s3_int2\n",
    "FORCE = TRUE\n",
    "ON_ERROR = CONTINUE\n",
    "  file_format = (type = csv FIELD_OPTIONALLY_ENCLOSED_BY = '\"' SKIP_HEADER=1 PARSE_HEADER = FALSE);\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
